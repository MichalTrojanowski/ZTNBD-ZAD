{"cells":[{"cell_type":"code","source":["import numpy as np\ndata = np.random.randint(0, 10, (100, 5)).tolist()\ndistData = sc.parallelize(data)\nprint(type(data[0][0]))"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":["## Od tąd zaczyna się moja część - poprzednia komórka to wygenerowanie mockowych danych - wektorów, których oczkuję od cześci Maćka."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import Row\nfrom pyspark.sql.types import * \nfrom pyspark.ml.linalg import Vectors\n\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Generowanie losowych labels\nrandomLabels = sc.parallelize(np.random.randint(0, 3, distData.count(), dtype=int).tolist())\n\n# Tworzenie DF-a z labels i features\ndataWithLabels = distData.zip(randomLabels)\ndataWithLabelsDF = dataWithLabels.map(lambda row: Row(label=row[1], features=Vectors.dense(row[0]))).toDF()\n\nevaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n\n# train test split - do testów\ntraining, test = dataWithLabelsDF.randomSplit([0.8, 0.2])\n\n# Uzywam LogisticRegression do klasyfikacji\nlr = LogisticRegression(maxIter=5, regParam=0.01)\n\n# Param grid do CrossValidation - pewnie będzie rozbudowany o transformery\ngrid = ParamGridBuilder() \\\n.addGrid(lr.maxIter, [5, 10]) \\\n.addGrid(lr.regParam, [0.01, 0.1]) \\\n.build()\ncv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator)\n\n# Trening\nmodel = cv.fit(training)\n\n# Testy na zbiorze testowym\nresults = model.transform(test)\n\n# Ewaluacja wyników - żałosna skuteczność przez losowość klas.\nevaluator.evaluate(results)"],"metadata":{},"outputs":[],"execution_count":3}],"metadata":{"name":"MLtest","notebookId":2982441594060328},"nbformat":4,"nbformat_minor":0}
